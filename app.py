import streamlit as st
import cv2
import tempfile
import os
from ultralytics import YOLO
import time
import numpy as np
from collections import defaultdict

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Created by Yun Seong #1 : ğŸ“¹OBJECT TRACE", layout="wide")

# 2. ê°•ë ¥í•œ ë ˆíŠ¸ë¡œ ë¸Œë£¨íƒˆë¦¬ì¦˜ CSS ì ìš©
st.markdown("""
    <style>
    /* 1. Source Code Pro í°íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸° */
    @import url('https://fonts.googleapis.com/css2?family=Source+Code+Pro:wght@400;700;900&display=swap');

    /* 2. ì „ì²´ ìš”ì†Œì— ì ìš© */
    html, body, [class*="css"], .main, stMarkdown, h1, p, button {
        font-family: 'Source Code Pro', monospace !important;
    }

    /* ì‚¬ì´ë“œë°” ìŠ¤íƒ€ì¼ë§ */
    [data-testid="stSidebar"] {
        background-color: #000000 !important;
        border-right: 3px solid #00ffff !important;
    }

    /* ëª¨ë“  í…ìŠ¤íŠ¸ ì»¬ëŸ¬ë¥¼ ì‚¬ì´ì–¸(Cyan)ìœ¼ë¡œ ê³ ì • */
    h1, h2, h3, h4, p, label, .stMarkdown, span, [data-testid="stMetricLabel"] {
        color: #00ffff !important;
        text-transform: uppercase !important;
    }

    /* ë©”ì¸ íƒ€ì´í‹€ ë°•ìŠ¤ ìŠ¤íƒ€ì¼ */
    .title-container {
        border: 2px solid #00ffff;
        padding: 20px;
        margin-bottom: 30px;
        display: inline-block;
        background-color: #000000;
    }
    .title-main {
        font-size: 40px !important;
        font-weight: 500 !important;
        line-height: 1.2;
        margin: 0;
        color: #00ffff !important;
    }

    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ (ë°˜ì „ íš¨ê³¼) */
    div.stButton > button:first-child {
        width: 100%;
        background-color: #000000 !important;
        color: #00ffff !important;
        border: 3px solid #00ffff !important;
        border-radius: 0px !important;
        font-weight: 800 !important;
        padding: 15px !important;
        transition: 0.2s;
        text-transform: uppercase;
    }
    div.stButton > button:first-child:hover {
        background-color: #00ffff !important;
        color: #000000 !important;
    }

    /* ë©”íŠ¸ë¦­ ë°•ìŠ¤ ì»¤ìŠ¤í…€ */
    [data-testid="stMetric"] {
        border: 2px solid #00ffff;
        padding: 15px;
        background-color: #000000;
    }
    [data-testid="stMetricValue"] {
        color: #00ffff !important;
    }

    /* ì—…ë¡œë” ë° ìŠ¬ë¼ì´ë” ìŠ¤íƒ€ì¼ */
    .stFileUploader, .stSlider {
        border: 1px dashed #00ffff;
        padding: 10px;
    }
    
    /* êµ¬ë¶„ì„  */
    hr {
        border-top: 4px double #00ffff !important;
    }

    /* Success/Error override */
    .stAlert {
        background-color: #000000 !important;
        border: 1px solid #00ffff !important;
        color: #00ffff !important;
    }

    /* 4. ë§ˆìš°ìŠ¤ ì»¤ì„œ ì‹­ìì„  ë° ë°˜ì „ ì„¤ì • */
    html, body, .main {
        cursor: crosshair !important;
    }

    /* í´ë¦­ ìš”ì†Œ ìœ„ì— ìˆì„ ë•Œ ì»¤ì„œ ë°˜ì „ íš¨ê³¼ */
    button, a, [data-testid="stFileUploadDropzone"], .stSlider {
        mix-blend-mode: difference; 
        cursor: crosshair !important;
    }
    </style>
    """, unsafe_allow_html=True)

# 3. ëª¨ë¸ ë¡œë“œ (ìºì‹œ ì‚¬ìš©)
@st.cache_resource
def load_model(model_name):
    return YOLO(model_name)

# 4. ì‚¬ì´ë“œë°” ì œì–´
with st.sidebar:
    st.markdown("### 01. SETUP")
    model_type = st.selectbox("MODEL_SELECT", ["yolov8n.pt", "yolov8s.pt", "yolov8m.pt"])
    confidence_threshold = st.slider("THRESHOLD", 0.0, 1.0, 0.4, 0.05)
    st.write("---")
    st.markdown("### STATUS: ACTIVE")

    try:
        model = load_model(model_type)
        st.success(f"SUCCESS: {model_type} LOADED")
    except Exception as e:
        st.error(f"ERROR: {e}")

# 5. ë©”ì¸ í™”ë©´ êµ¬ì„±
st.markdown('<div class="title-container"><p class="title-main">CREATED BY YUN SEONG #1 : ğŸ“¹ OBJECT TRACE</p></div>', unsafe_allow_html=True)

col_left, col_right = st.columns([3, 1])

with col_left:
    st.markdown("#### // VIDEO_INPUT")
    uploaded_file = st.file_uploader("UPLOAD_FILE", type=["mp4", "mov", "avi"])
    video_placeholder = st.empty()

with col_right:
    st.markdown("#### // ANALYTICS")
    metric_placeholder = st.empty()
    metric_placeholder.metric(label="ENTITIES_DETECTED", value="00", delta="SCANNING")
    st.write("---")
    status_text = st.empty()
    status_text.info("SYSTEM_READY: WAITING FOR INPUT...")

# 6. ë¶„ì„ ì—”ì§„ ì‹¤í–‰ (ê¶¤ì  ì¶”ì  ê¸°ëŠ¥ í†µí•©)
if uploaded_file is not None:
    tfile = tempfile.NamedTemporaryFile(delete=False)
    tfile.write(uploaded_file.read())
    video_path = tfile.name

    with col_left:
        video_placeholder.video(video_path)

    with col_right:
        if st.button("START ANALYSIS"):
            status_text.warning("ANALYZING...")
            
            cap = cv2.VideoCapture(video_path)
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = int(cap.get(cv2.CAP_PROP_FPS))
            
            output_path = os.path.join(tempfile.gettempdir(), "output_annotated.mp4")
            fourcc = cv2.VideoWriter_fourcc(*'mp4v') 
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

            st_frame = st.empty() 
            progress_bar = st.progress(0)
            
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            curr_frame = 0

            # ê¶¤ì  ì €ì¥ì„ ìœ„í•œ ë”•ì…”ë„ˆë¦¬ (IDë³„ ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸)
            track_history = defaultdict(lambda: [])

            while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            # --- ì´ ë¶€ë¶„ì„ ì¶”ê°€í•˜ì„¸ìš” ---
            # ì˜ìƒì„ 640px ë„ˆë¹„ë¡œ ë¦¬ì‚¬ì´ì§•í•˜ì—¬ ì—°ì‚°ëŸ‰ ê°ì†Œ
            analysis_frame = cv2.resize(frame, (640, int(height * (640 / width))))
            # --------------------------

            # ì•„ë˜ model.trackì˜ ëŒ€ìƒì„ frameì—ì„œ analysis_frameìœ¼ë¡œ ë³€ê²½
            results = model.track(analysis_frame, persist=True, conf=confidence_threshold)
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break

                # ê°ì²´ ì¶”ì  ì‹¤í–‰ (persist=True í•„ìˆ˜)
                results = model.track(frame, persist=True, conf=confidence_threshold)
                
                # YOLO ê¸°ë³¸ ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                annotated_frame = results[0].plot() 

                # ê¶¤ì  ì‹œê°í™” ë¡œì§ ì‹œì‘
                if results[0].boxes.id is not None:
                    # ë°•ìŠ¤ ì •ë³´(xywh)ì™€ í• ë‹¹ëœ ID ì¶”ì¶œ
                    boxes = results[0].boxes.xywh.cpu().numpy()
                    track_ids = results[0].boxes.id.int().cpu().tolist()

                    for box, track_id in zip(boxes, track_ids):
                        x, y, w, h = box
                        track = track_history[track_id]
                        track.append((float(x), float(y))) # ì¤‘ì‹¬ì  ì¶”ê°€
                        
                        # ê¶¤ì  ê¸¸ì´ ì¡°ì ˆ (ìµœê·¼ 30í”„ë ˆì„ í”ì  ìœ ì§€)
                        if len(track) > 20:
                            track.pop(0)

                        # ì´ë™ ê²½ë¡œ ì„ (Line) ê·¸ë¦¬ê¸°
                        points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))
                        cv2.polylines(annotated_frame, [points], isClosed=False, color=(255, 255, 0), thickness=2)
                        
                        # í˜„ì¬ ìœ„ì¹˜ ì (Dot) ì°ê¸°
                        cv2.circle(annotated_frame, (int(x), int(y)), 4, (0, 0, 255), -1)

                # ë¶„ì„ í”„ë ˆì„ ë¹„ë””ì˜¤ íŒŒì¼ë¡œ ì €ì¥
                out.write(annotated_frame)

                # ë©”ì¸ í™”ë©´ ì‹¤ì‹œê°„ ë Œë”ë§
                with col_left:
                    st_frame.image(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB), channels="RGB", use_container_width=True)
                
                # ìš°ì¸¡ ì§€í‘œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
                with col_right:
                    obj_count = len(results[0].boxes) if results[0].boxes.id is not None else 0
                    metric_placeholder.metric("ENTITIES_DETECTED", f"{obj_count:02d}", delta="ACTIVE")
                
                # ì§„í–‰ë¥  í‘œì‹œ
                curr_frame += 1
                if frame_count > 0:
                    progress_bar.progress(min(curr_frame / frame_count, 1.0))

            cap.release()
            out.release()
            
            status_text.success("SUCCESS: ANALYSIS_COMPLETE")
            
            # ë¶„ì„ ì™„ë£Œ ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ë§í¬ ì œê³µ
            with open(output_path, "rb") as file:
                st.download_button(
                    label="DOWNLOAD_PROCESSED_VIDEO",
                    data=file,
                    file_name="processed_video.mp4",
                    mime="video/mp4"
                )
